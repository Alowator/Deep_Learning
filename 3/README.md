1. Где расположен код модели и кто разработчик?

  * Код модели - https://github.com/sberbank-ai/sber-swap
  * Разработчики - Даниил Чесаков, Анастасия Мальцева, Александр Грошев, Андрей Кузнецов, Денис Димитров в компании **Сбербанк**, однако код выложен под свободной лицензией Apache License 2.0

2. Есть ли статья по работе модели? Если да, то в чем суть подхода авторов, как обучалась модель, какие метрики были достигнуты?

  * Статьи - https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9851423&tag=1
  https://habr.com/ru/companies/sberbank/articles/645919/
  * За основу авторы взяли подход из статьи FaceShifter, а также идеи из других статей, итоговый подход:
    1. Вырезаем лицо source изображения
    2. С помощью модели ArcFace извлекается вектор идентичности лица
    3. С помощью некоторой U-NET-like архитектуры извлекаются признаки taget лица
    4. Векторы последовательно смешиваются
  * Использовалась предобученная модель. Дообучивалась модель на датасетах VGG Face 2 и CelebA-HQ. Проводились эксперименты с разными функциями потерь: лосс идентичности, GAN лосс, лосс реконструкции и лосс атрибутов. Однако самым важным оказася лосс на глаза.
  * Соответсвенно существует много метрик, по которым можно оценивать качество получившейся модели, табличку с ними можно увидеть в статье на хабре. Одна из метрик - eye_ldmk отвечает за сохранение направления взгляда.

3. Состоит ли модель из нескольких частей? Если да, то из каких, что они делают и как называются в коде?

  * Да, модель состоит из частей:
    1. network.AEI_Net - базовая модель
    2. netArc - предобученная модель, с помощью которой получали вектор идентичности лица
    3. coordinate_reg.image_infer.Handler - модель для обнаружения ключевых точек лица
    4. Pix2PixModel - используется для улучшения качества получаемого изображения (качество ухудшают на стадии обучения, затем с помощью этой модедли увеличивают качество)

4. Как проходит процесс инференса модели для фото и видео (подробно)? Какие применяются преобразования входных и выходных данных?

  * Инференс видео - покадровый инференс фото, с учетом того, что в инференс передаются необработанные кадры, в которые нужно вставить лица, выровненные и обрезанные аффинным преобразованием из исходных изображений, а также выровненные лица, которые необходимо заменить, если на таргет-изображении присутствует несколько людей. Из таргет-кадров вырезаются лица, похожие на указанное, все обрезанные изображения подгоняются под размер 224x224, нормализуются и уменьшаются в два раза. Затем лица подаются на вход модели, результатом является обрезанное лицо, которое затем подвергается обратным преобразованиям. Если требуется, результат увеличивается в разрешении другой моделью (описано в пункте выше). Результат накладывается на целевое изображение с использованием полупрозрачной маски, которая создается на основе положения найденных ранее основных элементов лица

5. Можно ли дообучить модель и какие для этого требуются ресурсы? Может, авторы давали советы по обучению/дообучению? 

  * Прямых рекомендаций в статье не было, однако очевидно, что: как было описано выше, используется несколько функций потерь, от используемых функций потерь зависит итоговый результат. Модель можно дообучить используя тот же датасет VGG Face 2 и используя другие функции потерь или их параметры.
